{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Loading dataset...\n",
      "Preparing datasets...\n",
      "Train set size: 400, Test set size: 100\n",
      "Balancing dataset...\n",
      "Final Balanced Dataset - Positive: 240, Negative: 160\n",
      "Final Train set size: 400, Test set size: 100\n",
      "Initializing QSVM...\n",
      "Applying PCA...\n",
      "PCA Variance Ratio: 1.0000\n",
      "Initializing quantum kernel...\n",
      "Training QSVM...\n",
      "QSVM training complete. Time taken: 9.75 minutes.\n",
      "Evaluating QSVM...\n",
      "QSVM evaluation complete. Time taken: 4.38 minutes.\n",
      "QSVM Accuracy: 0.6000\n",
      "Precision: 0.5625\n",
      "Recall: 0.6000\n",
      "F1 Score: 0.4825\n",
      "Confusion Matrix:\n",
      " [[ 2 38]\n",
      " [ 2 58]]\n",
      "Saving QSVM model...\n",
      "QSVM model saved to qsvm_smallmodel.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib  # For model saving/loading\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Limit dataset size to prevent memory issues\n",
    "#MAX_SAMPLES = 2500   \n",
    "\n",
    "class QSVM:\n",
    "    def __init__(self, data, pca_components, reps=1):\n",
    "        print(\"Initializing QSVM...\")\n",
    "        self.data = data\n",
    "        self.pca_components = pca_components\n",
    "        self.reps = reps\n",
    "        self.apply_pca()\n",
    "        self.initialize_quantum_kernel()\n",
    "\n",
    "    def apply_pca(self):\n",
    "        \"\"\"Reduce feature dimensions using PCA\"\"\"\n",
    "        print(\"Applying PCA...\")\n",
    "        pca = PCA(n_components=self.pca_components)\n",
    "        self.data.train_features = pca.fit_transform(self.data.train_features)\n",
    "        self.data.test_features = pca.transform(self.data.test_features)\n",
    "        print(f\"PCA Variance Ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "    def initialize_quantum_kernel(self):\n",
    "        \"\"\"Set up the quantum feature map and fidelity kernel\"\"\"\n",
    "        print(\"Initializing quantum kernel...\")\n",
    "        feature_map = ZZFeatureMap(feature_dimension=self.pca_components, reps=self.reps, entanglement=\"linear\")\n",
    "        self.quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Train QSVM on quantum kernel\"\"\"\n",
    "        print(\"Training QSVM...\")\n",
    "        start_time = time.time()\n",
    "        self.qsvc = QSVC(quantum_kernel=self.quantum_kernel, C=0.7)\n",
    "        self.qsvc.fit(self.data.train_features, self.data.train_labels)\n",
    "        end_time = time.time()\n",
    "        print(f\"QSVM training complete. Time taken: {(end_time - start_time) / 60:.2f} minutes.\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate QSVM using accuracy metrics\"\"\"\n",
    "        print(\"Evaluating QSVM...\")\n",
    "        start_time = time.time()\n",
    "        predictions = self.qsvc.predict(self.data.test_features)\n",
    "        end_time = time.time()\n",
    "        print(f\"QSVM evaluation complete. Time taken: {(end_time - start_time) / 60:.2f} minutes.\")\n",
    "        acc = accuracy_score(self.data.test_labels, predictions)\n",
    "        prec = precision_score(self.data.test_labels, predictions, average=\"weighted\")\n",
    "        rec = recall_score(self.data.test_labels, predictions, average=\"weighted\")\n",
    "        f1 = f1_score(self.data.test_labels, predictions, average=\"weighted\")\n",
    "        conf_matrix = confusion_matrix(self.data.test_labels, predictions)\n",
    "\n",
    "        print(f\"QSVM Accuracy: {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall: {rec:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "        return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1, \"confusion_matrix\": conf_matrix}\n",
    "\n",
    "    def save_model(self, filename=\"Saved_Models/qsvm_smallmodel.pkl\"):\n",
    "        \"\"\"Save the trained QSVM model\"\"\"\n",
    "        if not hasattr(self, \"qsvc\") or self.qsvc is None:\n",
    "            print(\"Error: No trained model found. Train the QSVM first.\")\n",
    "            return\n",
    "\n",
    "        print(\"Saving QSVM model...\")\n",
    "        joblib.dump(self.qsvc, filename)\n",
    "        print(f\"QSVM model saved to {filename}\")\n",
    "\n",
    "    def load_model(self, filename=\"Saved_Models/qsvm_smallmodel.pkl\"):\n",
    "        \"\"\"Load a previously saved QSVM model\"\"\"\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"Error: Model file {filename} not found.\")\n",
    "            return\n",
    "\n",
    "        print(\"Loading QSVM model...\")\n",
    "        self.qsvc = joblib.load(filename)\n",
    "        print(f\"QSVM model loaded from {filename}\")\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, filename):\n",
    "        print(\"Initializing dataset...\")\n",
    "        self.filename = filename\n",
    "        self.load_data()\n",
    "        self.prepare_datasets()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load dataset and apply necessary preprocessing\"\"\"\n",
    "        print(\"Loading dataset...\")\n",
    "        self.df = pd.read_csv(self.filename)\n",
    "        #self.df = self.df[:MAX_SAMPLES]  # Limit dataset size\n",
    "\n",
    "        # Feature Selection: Drop weakly correlated features\n",
    "        #self.df.drop(columns=['Gender', 'HeartRate'], inplace=True)\n",
    "\n",
    "    def prepare_datasets(self):\n",
    "        \"\"\"Split dataset into train/test, scale features, and balance data\"\"\"\n",
    "        print(\"Preparing datasets...\")\n",
    "\n",
    "        # Extract features and labels before splitting\n",
    "        features = self.df.drop(columns=[\"HeartDisease\"]).to_numpy()\n",
    "        labels = self.df[\"HeartDisease\"].to_numpy()\n",
    "\n",
    "        # Scale features before splitting to ensure consistency\n",
    "        scaler = MinMaxScaler(feature_range=(0, 2 * np.pi))\n",
    "        features = scaler.fit_transform(features)\n",
    "\n",
    "        # Stratified split to maintain class distribution\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "            features, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"Train set size: {len(train_features)}, Test set size: {len(test_features)}\")\n",
    "\n",
    "        # Balance only the training data\n",
    "        train_features, train_labels = self.balance_data(train_features, train_labels)\n",
    "\n",
    "        # Store processed features and labels\n",
    "        self.train_features, self.train_labels = train_features, train_labels\n",
    "        self.test_features, self.test_labels = test_features, test_labels\n",
    "\n",
    "        print(f\"Final Train set size: {len(self.train_features)}, Test set size: {len(self.test_features)}\")\n",
    "\n",
    "    def balance_data(self, features, labels, target_ratio=0.01):\n",
    "        \"\"\"Balance dataset by undersampling majority class\"\"\"\n",
    "        print(\"Balancing dataset...\")\n",
    "\n",
    "        df_balanced = pd.DataFrame(features)\n",
    "        df_balanced[\"HeartDisease\"] = labels  # Reintroduce labels into a DataFrame\n",
    "\n",
    "        df_positive = df_balanced[df_balanced[\"HeartDisease\"] == 1]  # Majority class\n",
    "        df_negative = df_balanced[df_balanced[\"HeartDisease\"] == 0]  # Minority class\n",
    "\n",
    "        # Determine the sample size for balancing\n",
    "        sample_size = min(len(df_positive), int(len(df_negative) / target_ratio))\n",
    "\n",
    "        if sample_size < len(df_positive):  # Only sample if required\n",
    "            df_positive_sampled = df_positive.sample(n=sample_size, random_state=42)\n",
    "        else:\n",
    "            df_positive_sampled = df_positive  # No need to sample if already balanced\n",
    "\n",
    "        # Combine and shuffle\n",
    "        balanced_df = pd.concat([df_positive_sampled, df_negative]).sample(frac=1, random_state=42)\n",
    "\n",
    "        print(f\"Final Balanced Dataset - Positive: {len(df_positive_sampled)}, Negative: {len(df_negative)}\")\n",
    "\n",
    "        # Extract features and labels back as NumPy arrays\n",
    "        return balanced_df.drop(columns=[\"HeartDisease\"]).to_numpy(), balanced_df[\"HeartDisease\"].to_numpy()\n",
    "\n",
    "\n",
    "# Load dataset and train QSVM\n",
    "dataset = Data('Heart Prediction Quantum Dataset.csv')\n",
    "qsvm = QSVM(dataset, pca_components=6, reps=2)\n",
    "qsvm.fit()\n",
    "\n",
    "# Evaluate QSVM performance\n",
    "metrics = qsvm.evaluate()\n",
    "\n",
    "# Save the trained model for later use\n",
    "qsvm.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
